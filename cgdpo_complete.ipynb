{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752b144e-8898-4bc4-9caf-656e6ecc872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b7950a-d7a1-4ff7-a5ca-2e4f30e76bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_num = 1 \n",
    "dev = 'cuda:%d'%cuda_num\n",
    "seed = 0\n",
    "folder = 'cgdpo_complete'\n",
    "if not os.path.exists(folder) :\n",
    "    os.mkdir(folder)\n",
    "\n",
    "torch.set_printoptions(sci_mode=False,precision=4)\n",
    "np.set_printoptions(suppress=True,precision=4,linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc6927d-22cb-4701-a451-16b235e723f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.18\n",
    "r = 0.07\n",
    "vol = 0.3\n",
    "gamma = 2.\n",
    "rho = 0.1\n",
    "eps = 0.1\n",
    "\n",
    "m = 5\n",
    "n = int(1e3)\n",
    "\n",
    "T_max = 1.\n",
    "W_min = 1e-1\n",
    "W_max = 2.\n",
    "lb_w = 1e-4\n",
    "lb_c = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57c9a00-2e7a-40d2-b32c-905d03c3fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyopicNet(nn.Module) :\n",
    " \n",
    "    def __init__(self) :\n",
    "        super(MyopicNet,self).__init__()\n",
    "        \n",
    "        self.linear1a = nn.Linear(2,200)\n",
    "        self.linear2a = nn.Linear(200,200)\n",
    "        self.linear3a = nn.Linear(200,200)\n",
    "        self.linear4a = nn.Linear(200,1)\n",
    "        \n",
    "        self.F = nn.LeakyReLU()\n",
    "        self.H = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x0) :\n",
    "\n",
    "        xa = torch.zeros_like(x0[:,0:2])\n",
    "        \n",
    "        xa = self.linear1a(xa)\n",
    "        xa = self.F(xa)\n",
    "        xa = self.linear2a(xa)\n",
    "        xa = self.F(xa)\n",
    "        xa = self.linear3a(xa)\n",
    "        xa = self.F(xa)\n",
    "        xa = self.linear4a(xa)\n",
    "\n",
    "        return xa.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442a7ac0-07a4-4ff1-9699-452a7a8228a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsumeNet(nn.Module) :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super(ConsumeNet,self).__init__()\n",
    "        \n",
    "        self.linear1a = nn.Linear(2,200)\n",
    "        self.linear2a = nn.Linear(200,200)\n",
    "        self.linear3a = nn.Linear(200,200)\n",
    "        self.linear4a = nn.Linear(200,1)\n",
    "        \n",
    "        self.F = nn.LeakyReLU()\n",
    "        self.H = nn.Softplus()\n",
    "        \n",
    "    def forward(self,x0) :\n",
    "\n",
    "        xa = x0\n",
    "       \n",
    "        xa = self.linear1a(xa)\n",
    "        xa = self.F(xa)\n",
    "        xa = self.linear2a(xa)\n",
    "        xa = self.F(xa)\n",
    "        xa = self.linear3a(xa)\n",
    "        xa = self.F(xa)\n",
    "        xa = self.linear4a(xa)\n",
    "        xa = self.H(xa)\n",
    "        \n",
    "        return xa.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf5c8c3-5196-4bcc-8d17-526c90d3c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "net_c = ConsumeNet()\n",
    "net_c = net_c.to(dev)\n",
    "\n",
    "net_m = MyopicNet()\n",
    "net_m = net_m.to(dev)\n",
    "\n",
    "opt_c = torch.optim.Adam(net_c.parameters(),lr=1e-5)\n",
    "opt_m = torch.optim.Adam(net_m.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c9461a-aa7a-4e66-b1ff-67cc69f73573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniform_domain(n) :\n",
    "\n",
    "    T = T_max*torch.rand([n],device=dev)\n",
    "    dt = T/m\n",
    "    W = W_min + (W_max-W_min)*torch.rand([n],device=dev)\n",
    "\n",
    "    return T,W,dt\n",
    "\n",
    "T,W,dt = generate_uniform_domain(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6212c85f-49a0-4a06-9ccc-9ab3527befc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nu() :\n",
    "    nu = rho - (1.-gamma)*( (mu-r)**2/(2.*vol**2*gamma) + r )\n",
    "    nu = nu/gamma\n",
    "    return nu    \n",
    "\n",
    "def get_consume(x, t) :\n",
    "    nu = get_nu()\n",
    "    c = nu*x\n",
    "    c /= (1.+(nu*eps-1.)*np.exp(-nu*t))\n",
    "    return c\n",
    "\n",
    "def get_myopic(x, t) :\n",
    "    return (mu-r)/(vol**2*gamma)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8c0f1c-2742-404d-883c-d0a4c3572fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(xx) :\n",
    "\n",
    "    xx.requires_grad = True\n",
    "\n",
    "    a_c = net_c(xx)\n",
    "    \n",
    "    grad_outputs = torch.ones_like(a_c) \n",
    "    d1 = torch.autograd.grad(a_c, xx, grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    d11 = torch.autograd.grad(d1[:,0], xx, grad_outputs=grad_outputs, create_graph=True)[0][:,0:1].detach()\n",
    "    d22 = torch.autograd.grad(d1[:,1], xx, grad_outputs=grad_outputs, create_graph=True)[0][:,1:2].detach()\n",
    "\n",
    "    d11 = torch.sqrt(d11**2/torch.sum(d11**2))\n",
    "    d22 = torch.sqrt(d22**2/torch.sum(d22**2))\n",
    "    d2 = torch.cat([d11,d22],axis=1).detach()\n",
    "    std = torch.sum(d2**2,axis=1,keepdims=True)\n",
    "\n",
    "    xx.requires_grad = False\n",
    "\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059eb3d8-824f-4cc8-97c3-c81762dd777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sampling_torch(vector, num_samples):\n",
    "    tensor = torch.tensor(vector, dtype=torch.float)\n",
    "    weights = torch.linspace(1, 0.1, len(vector))**2\n",
    "    probabilities = weights / weights.sum()\n",
    "    sampled_indices = torch.multinomial(probabilities, num_samples, replacement=False)\n",
    "    samples = tensor[sampled_indices].tolist()\n",
    "    return samples\n",
    "\n",
    "def generate_domain_adaptive_sampling(n) :\n",
    "\n",
    "    T,W,dt = generate_uniform_domain(5*n)\n",
    "    \n",
    "    xx = torch.rand([5*n,2],device=dev)\n",
    "    xx[:,0] = W\n",
    "    xx[:,1] = T\n",
    "\n",
    "    std = measure(xx)\n",
    "    W = W.reshape(-1)\n",
    "    T = T.reshape(-1)\n",
    "    std = std.reshape(-1)\n",
    "\n",
    "    idx = torch.argsort(std,descending=True)\n",
    "    n_sample = int(0.9*n)\n",
    "    sample = weighted_sampling_torch(torch.arange(len(idx),device=dev), n_sample)\n",
    "    W2 = W[idx][sample]\n",
    "    T2 = T[idx][sample]\n",
    "    \n",
    "    T1 = T_max*torch.rand([n-n_sample],device=dev)\n",
    "    T = torch.hstack([T1,T2])\n",
    "    dt = T/m\n",
    "    \n",
    "    W1 = W_min + (W_max-W_min)*torch.rand([n-n_sample],device=dev)\n",
    "    W = torch.hstack([W1,W2])\n",
    "\n",
    "    return T,W,dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94afe8fb-5175-4393-93c1-50e3f1396e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(iter,min,save,U,case,lr_c,lr_m) :\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if not save :\n",
    "        iter = -1\n",
    "\n",
    "    def draw(x,t,u,filename) :\n",
    "        \n",
    "        tmp = u\n",
    "        tmp = np.sort(tmp)\n",
    "        m = 100\n",
    "        n = (len(tmp)-1)//m\n",
    "        levels = [tmp[i*n] for i in range(m+1)]\n",
    "        levels[-1] = tmp[-1]\n",
    "    \n",
    "        color_map = plt.cm.jet\n",
    "        colors = color_map(np.linspace(0, 1, m+1))\n",
    "    \n",
    "        plt.figure(figsize=(6.5,5))\n",
    "        plt.plot(x, t, 'o', markersize=0.5, alpha=0.5, color='grey')\n",
    "        try :\n",
    "            contourf_plot = plt.tricontourf(x,t,u,levels=levels,colors=colors)\n",
    "        except :\n",
    "            contourf_plot = plt.tricontourf(x,t,u)\n",
    "        plt.xlabel('W')\n",
    "        plt.ylabel('T-t')\n",
    "        plt.colorbar(contourf_plot)\n",
    "\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "    # ************************************************************************************************** #\n",
    "\n",
    "    T,W,dt = generate_domain_adaptive_sampling(10000)\n",
    "\n",
    "    xx = torch.rand([10000,2],device=dev)\n",
    "    xx[:,0] = W\n",
    "    xx[:,1] = T\n",
    "\n",
    "    std = measure(xx)\n",
    "    x = xx[:,0].clone().cpu().numpy()\n",
    "    t = xx[:,1].clone().cpu().numpy()\n",
    "    std = std.detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(5.2,5.2))\n",
    "    plt.plot(x, t, 'o', markersize=0.5, alpha=0.5, color='grey')\n",
    "    plt.xlabel('W'); plt.xlim([0,W_max])\n",
    "    plt.ylabel('T-t'); plt.ylim([0,T_max])\n",
    "    plt.grid()\n",
    "    plt.savefig('%s/sampling_points_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    plt.close()\n",
    "\n",
    "    # ************************************************************************************************** #\n",
    "\n",
    "    T,W,dt = generate_uniform_domain(10000)\n",
    "    \n",
    "    xx = torch.rand([10000,2],device=dev)\n",
    "    xx[:,0] = W\n",
    "    xx[:,1] = T\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        a_c = net_c(xx)\n",
    "        a_m = net_m(xx)\n",
    "        \n",
    "    a_c = a_c.detach().cpu().numpy()\n",
    "    a_m = a_m.detach().cpu().numpy()\n",
    "    x = xx[:,0].clone().cpu().numpy()\n",
    "    t = xx[:,1].clone().cpu().numpy()\n",
    "\n",
    "    a_c = a_c*x/(t+lb_c)\n",
    "    a_m = a_m*x   \n",
    "    \n",
    "    c_sol = get_consume(x,t)\n",
    "    m_sol = get_myopic(x,t)\n",
    "\n",
    "    draw(x,t,a_c,'%s/c_net_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    draw(x,t,c_sol,'%s/c_sol_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    draw(x,t,a_c-c_sol,'%s/c_err_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    err_c = np.sqrt( np.mean((a_c-c_sol)**2/c_sol**2) )\n",
    "\n",
    "    draw(x,t,a_m,'%s/m_net_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    draw(x,t,m_sol,'%s/m_sol_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    draw(x,t,a_m-m_sol,'%s/m_err_case_%d_iter_%d.png'%(folder,case,iter))\n",
    "    err_m = np.sqrt( np.mean((a_m-m_sol)**2/m_sol**2) )\n",
    "\n",
    "    with open('%s/errs_case_%d_iter_%d.txt'%(folder,case,iter),'wt') as f :\n",
    "        print(\"i: %d  min: %d  err_c: %10.6e  err_m: %10.6e  U: %10.6e  lr_c: %10.3e  lr_m: %10.3e\"%(i,min,err_c,err_m,U,lr_c,lr_m),file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e43ef7-4a40-4a49-8930-e365819619ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552717/3157048381.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(vector, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "min = 0\n",
    "lr_c = opt_c.param_groups[0]['lr']\n",
    "lr_m = opt_m.param_groups[0]['lr']\n",
    "plot(i,min,False,0,0,lr_c,lr_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20aced4-c43d-43d7-8ef4-3941e247985a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1316120/3157048381.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(vector, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_min:     0  target_min:     1  last_min:   480\n",
      "current_min:     1  target_min:     1  last_min:   480 --> saved\n",
      "current_min:     2  target_min:     5  last_min:   480\n",
      "current_min:     5  target_min:     5  last_min:   480 --> saved\n",
      "current_min:     5  target_min:    10  last_min:   480\n",
      "current_min:     8  target_min:    10  last_min:   480\n",
      "current_min:    10  target_min:    10  last_min:   480 --> saved\n",
      "current_min:    11  target_min:    30  last_min:   480\n",
      "current_min:    14  target_min:    30  last_min:   480\n",
      "current_min:    17  target_min:    30  last_min:   480\n",
      "current_min:    20  target_min:    30  last_min:   480\n",
      "current_min:    23  target_min:    30  last_min:   480\n",
      "current_min:    26  target_min:    30  last_min:   480\n",
      "current_min:    29  target_min:    30  last_min:   480\n",
      "current_min:    30  target_min:    30  last_min:   480 --> saved\n",
      "current_min:    32  target_min:    60  last_min:   480\n",
      "current_min:    35  target_min:    60  last_min:   480\n",
      "current_min:    38  target_min:    60  last_min:   480\n",
      "current_min:    41  target_min:    60  last_min:   480\n",
      "current_min:    44  target_min:    60  last_min:   480\n",
      "current_min:    47  target_min:    60  last_min:   480\n",
      "current_min:    50  target_min:    60  last_min:   480\n",
      "current_min:    53  target_min:    60  last_min:   480\n",
      "current_min:    56  target_min:    60  last_min:   480\n",
      "current_min:    59  target_min:    60  last_min:   480\n",
      "current_min:    60  target_min:    60  last_min:   480 --> saved\n",
      "current_min:    62  target_min:   120  last_min:   480\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m opt_c\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m opt_m\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m T,W,dt \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_domain_adaptive_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m U \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m) :\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mgenerate_domain_adaptive_sampling\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     14\u001b[0m xx[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m W\n\u001b[1;32m     15\u001b[0m xx[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m T\n\u001b[0;32m---> 17\u001b[0m std \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m W \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m T \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmeasure\u001b[0;34m(xx)\u001b[0m\n\u001b[1;32m      7\u001b[0m grad_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(a_c) \n\u001b[1;32m      8\u001b[0m d1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(a_c, xx, grad_outputs\u001b[38;5;241m=\u001b[39mgrad_outputs, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m d11 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43md1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     10\u001b[0m d22 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(d1[:,\u001b[38;5;241m1\u001b[39m], xx, grad_outputs\u001b[38;5;241m=\u001b[39mgrad_outputs, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     12\u001b[0m d11 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(d11\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(d11\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/pt20_py310/lib/python3.10/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mins = np.array([1,5,10,30,60])\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "net_c = ConsumeNet()\n",
    "net_c = net_c.to(dev)\n",
    "opt_c = torch.optim.Adam(net_c.parameters(),lr=1e-5)\n",
    "\n",
    "net_m = MyopicNet()\n",
    "net_m = net_m.to(dev)\n",
    "opt_m = torch.optim.Adam(net_m.parameters(),lr=1e-3)\n",
    "\n",
    "flag_write = False\n",
    "flag_draw = False\n",
    "flag_exit = False\n",
    "i = 0; mins_idx = 0\n",
    "start_time = time.time()\n",
    "start_time_draw = time.time()\n",
    "draw_time = 0.\n",
    "\n",
    "while True :\n",
    "\n",
    "    # ************************************************************************************************** #\n",
    "\n",
    "    opt_c.zero_grad()\n",
    "    opt_m.zero_grad()\n",
    "\n",
    "    T,W,dt = generate_domain_adaptive_sampling(n)\n",
    "\n",
    "    U = 0.\n",
    "    for k in range(m) :\n",
    "        t = k*dt\n",
    "\n",
    "        state = torch.vstack([W,T-t]).T\n",
    "        a_c = net_c(state)*W/(T-t+lb_c)\n",
    "            \n",
    "        W = W - a_c*dt\n",
    "        W = torch.relu(W - lb_w) + lb_w\n",
    "\n",
    "        U = U + torch.exp(-rho*t) * a_c**(1-gamma)/(1-gamma) * (1.-torch.exp(-rho*dt))/rho\n",
    "        \n",
    "        state = torch.vstack([W,T-t]).T\n",
    "        pi = net_m(state)      \n",
    "        \n",
    "        dZ = torch.randn([n],device=dev)*torch.sqrt(dt)\n",
    "        W = W*torch.exp( (mu*pi + r*(1-pi) - 0.5*vol**2*pi**2 )*dt + vol*pi*dZ )\n",
    "        W = torch.relu(W - lb_w) + lb_w\n",
    "\n",
    "    t = T\n",
    "    \n",
    "    U = U + torch.exp(-rho*t) *eps**gamma * W**(1-gamma)/(1-gamma)     \n",
    "    U = -U.nanmean()\n",
    "    U.backward()\n",
    "   \n",
    "    max_norm = 0.01\n",
    "    torch.nn.utils.clip_grad_norm_(net_c.parameters(), max_norm)\n",
    "    torch.nn.utils.clip_grad_norm_(net_m.parameters(), max_norm)\n",
    "\n",
    "    opt_c.step()\n",
    "    opt_m.step()\n",
    "\n",
    "    # ************************************************************************************************** #\n",
    "\n",
    "    time_i = time.time()\n",
    "    elapsed_time = time_i - start_time - draw_time\n",
    "    current_min = int(elapsed_time//60)\n",
    "    elapsed_time_draw = time_i - start_time_draw\n",
    "    \n",
    "    target_min = mins[mins_idx]\n",
    "    current_set_time = 60*target_min\n",
    "    last_set_time = 60*mins[-1]\n",
    "    \n",
    "    if elapsed_time_draw > 60*3 : \n",
    "        start_time_draw = time.time()\n",
    "        flag_draw = True\n",
    "    \n",
    "    if elapsed_time > current_set_time : \n",
    "        flag_write = True\n",
    "        mins_idx = mins_idx + 1\n",
    "        \n",
    "    if elapsed_time > last_set_time :\n",
    "        flag_exit = True\n",
    "\n",
    "    lr_c = opt_c.param_groups[0]['lr']\n",
    "    lr_m = opt_m.param_groups[0]['lr']\n",
    "    \n",
    "    if not flag_write :\n",
    "        if flag_draw or i == 0 :\n",
    "            print('current_min: %5d  target_min: %5d  last_min: %5d'%(current_min,target_min,mins[-1]))\n",
    "            plot(i,current_min,False,U,0,lr_c,lr_m)\n",
    "            flag_draw = False\n",
    "        \n",
    "    elif flag_write :\n",
    "        print('current_min: %5d  target_min: %5d  last_min: %5d'%(current_min,target_min,mins[-1]),'-->','saved')\n",
    "        plot(i,current_min,True,U,0,lr_c,lr_m)\n",
    "        flag_write = False    \n",
    "\n",
    "    draw_time = draw_time + (time.time() - time_i)\n",
    "\n",
    "    if flag_exit : break\n",
    "    i = i+1        \n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655208d-30f7-40a8-adab-d879d116f53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
